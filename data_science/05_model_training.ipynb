{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philipp-lampert/mymandible/blob/main/data_science/05_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umTBTdUKiRSB"
      },
      "source": [
        "#Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDIWPXifiG-K",
        "outputId": "1ace9ce2-5688-4497-8aba-fc2b75b28a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install notebook scikit-learn-intelex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-jK_YwJ5guh",
        "outputId": "abc5ab2d-320a-473c-d66a-70fdcdd95982"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (6.5.5)\n",
            "Collecting scikit-learn-intelex\n",
            "  Downloading scikit_learn_intelex-2024.0.1-py310-none-manylinux1_x86_64.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.7/122.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook) (3.1.2)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from notebook) (6.3.2)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook) (23.1.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.10/dist-packages (from notebook) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.10/dist-packages (from notebook) (6.1.12)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from notebook) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook) (1.5.8)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from notebook) (5.5.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook) (1.0.0)\n",
            "Collecting daal4py==2024.0.1 (from scikit-learn-intelex)\n",
            "  Downloading daal4py-2024.0.1-py310-none-manylinux1_x86_64.whl (10.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-intelex) (1.2.2)\n",
            "Collecting daal==2024.0.1 (from daal4py==2024.0.1->scikit-learn-intelex)\n",
            "  Downloading daal-2024.0.1-py2.py3-none-manylinux1_x86_64.whl (76.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from daal4py==2024.0.1->scikit-learn-intelex) (1.23.5)\n",
            "Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.10/dist-packages (from daal==2024.0.1->daal4py==2024.0.1->scikit-learn-intelex) (2021.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8,>=5.3.4->notebook) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook) (4.0.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (23.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (1.5.0)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (2.16.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook) (4.19.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->scikit-learn-intelex) (3.2.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook) (21.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->notebook) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->notebook)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (3.0.41)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->notebook) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook) (0.13.2)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook) (1.6.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client<8,>=5.3.4->notebook) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook) (2.21)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->notebook) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook) (0.2.12)\n",
            "Installing collected packages: jedi, daal, daal4py, scikit-learn-intelex\n",
            "Successfully installed daal-2024.0.1 daal4py-2024.0.1 jedi-0.19.1 scikit-learn-intelex-2024.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA4FIK6iyWgj",
        "outputId": "a85b7d16-c2aa-4783-e434-942af00722e9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler, Normalizer, QuantileTransformer\n",
        "from sklearn.metrics import make_scorer, matthews_corrcoef, f1_score, accuracy_score, average_precision_score, roc_auc_score\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold, HalvingGridSearchCV"
      ],
      "metadata": {
        "id": "YUwr51evyVpD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "o1ojEJRpI9Mh"
      },
      "outputs": [],
      "source": [
        "df_dropped_first_cca = pd.read_parquet('/content/drive/MyDrive/mymandible/data_science/data/dropped_first_cca.parquet')\n",
        "df_dropped_first_imp = pd.read_parquet('/content/drive/MyDrive/mymandible/data_science/data/dropped_first_imputed.parquet')\n",
        "\n",
        "df_all_levels_cca = pd.read_parquet('/content/drive/MyDrive/mymandible/data_science/data/all_levels_cca.parquet')\n",
        "df_all_levels_imp = pd.read_parquet('/content/drive/MyDrive/mymandible/data_science/data/all_levels_imputed.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp7wrq6knWcQ"
      },
      "source": [
        "We first define a function that imports the prepared CCA and imputed datasets and splits them into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4di1gihVdYTd"
      },
      "outputs": [],
      "source": [
        "def get_x_y(df, outcome, min_follow_up_days, scaling, remove_cols):\n",
        "\n",
        "  first_outcome_var = df.columns.get_loc('days_to_follow_up')\n",
        "  predictors = df.columns[:first_outcome_var].tolist()\n",
        "\n",
        "  data = df[df['days_to_follow_up'] >= min_follow_up_days].copy()\n",
        "  data['days_to_flap_loss'] = data['days_to_flap_loss'].fillna(10000)\n",
        "  data = data[data['days_to_flap_loss'] >= min_follow_up_days]\n",
        "  data = data[predictors + [outcome]].dropna()\n",
        "\n",
        "  data.drop(remove_cols, axis=1)\n",
        "\n",
        "  if scaling != False:\n",
        "    numeric_columns = data[predictors].select_dtypes(np.number).columns.tolist()\n",
        "    scaler = scaling\n",
        "    data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
        "\n",
        "  return data[predictors], data[outcome]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Pcujf-i2Cq8y"
      },
      "outputs": [],
      "source": [
        "def optimized_accuracy(y_test, y_pred):\n",
        "  thresholds = np.arange(0.1, 0.9, 0.05)\n",
        "  best_acc = 0\n",
        "\n",
        "  for threshold in thresholds:\n",
        "    predicted_labels = (y_pred >= threshold).astype(int)\n",
        "    acc = accuracy_score(y_test, predicted_labels)\n",
        "    if acc > best_acc:\n",
        "      best_acc = acc\n",
        "\n",
        "  return best_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "fSenqBWCr7Id"
      },
      "outputs": [],
      "source": [
        "def optimized_f1(y_test, y_pred):\n",
        "  thresholds = np.arange(0.1, 0.9, 0.05)\n",
        "  best_f1 = 0\n",
        "\n",
        "  for threshold in thresholds:\n",
        "    predicted_labels = (y_pred >= threshold).astype(int)\n",
        "    f1 = f1_score(y_test, predicted_labels)\n",
        "    if f1 > best_f1:\n",
        "      best_f1 = f1\n",
        "\n",
        "  return best_f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mOPgguC6AXC9"
      },
      "outputs": [],
      "source": [
        "def optimized_mcc(y_test, y_pred):\n",
        "  thresholds = np.arange(0.1, 0.9, 0.05)\n",
        "  best_mcc = -1\n",
        "\n",
        "  for threshold in thresholds:\n",
        "    predicted_labels = (y_pred >= threshold).astype(int)\n",
        "    mcc = matthews_corrcoef(y_test, predicted_labels)\n",
        "    if mcc > best_mcc:\n",
        "        best_mcc = mcc\n",
        "\n",
        "  return best_mcc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3oU-8gHKY6Pt"
      },
      "outputs": [],
      "source": [
        "#Make scoring functions\n",
        "acc_scorer = make_scorer(optimized_accuracy, needs_proba=True)\n",
        "f1_scorer = make_scorer(optimized_f1, needs_proba=True)\n",
        "mcc_scorer = make_scorer(optimized_mcc, needs_proba=True)\n",
        "\n",
        "# Declare the inner and outer cross-validation strategies\n",
        "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
        "outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
        "\n",
        "def nested_cv(outcome, model, parameter_grid, min_follow_up_days, scaling, df, remove_cols):\n",
        "\n",
        "  x, y = get_x_y(df, outcome, min_follow_up_days, scaling, remove_cols)\n",
        "\n",
        "  # Inner cross-validation for parameter search\n",
        "  inner_model = HalvingGridSearchCV(estimator=model, param_grid=parameter_grid, cv=inner_cv, n_jobs=-1, factor=2, scoring='average_precision')\n",
        "\n",
        "  # Outer cross-validation to compute the testing score\n",
        "  cv_results = cross_validate(inner_model, x, y, cv=outer_cv, n_jobs=-1, scoring={'mcc': mcc_scorer, 'f1': f1_scorer, 'accuracy': acc_scorer, 'pr_auc': 'average_precision', 'roc_auc': 'roc_auc'})\n",
        "\n",
        "  print(\"Mean MCC: \"\n",
        "      f\"{cv_results['test_mcc'].mean():.3f} ± {cv_results['test_mcc'].std():.3f}\")\n",
        "  print(\"Mean F1: \"\n",
        "      f\"{cv_results['test_f1'].mean():.3f} ± {cv_results['test_f1'].std():.3f}\")\n",
        "  print(\"Mean Accuracy: \"\n",
        "      f\"{cv_results['test_accuracy'].mean():.3f} ± {cv_results['test_accuracy'].std():.3f}\")\n",
        "  print(\"Mean PR AUC: \"\n",
        "      f\"{cv_results['test_pr_auc'].mean():.3f} ± {cv_results['test_pr_auc'].std():.3f}\")\n",
        "  print(\"Mean ROC AUC: \"\n",
        "      f\"{cv_results['test_roc_auc'].mean():.3f} ± {cv_results['test_roc_auc'].std():.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold, RepeatedStratifiedKFold, HalvingGridSearchCV\n",
        "from sklearn.metrics import make_scorer, matthews_corrcoef, f1_score, accuracy_score, average_precision_score, roc_auc_score\n",
        "\n",
        "#Make scoring functions\n",
        "acc_scorer = make_scorer(optimized_accuracy, needs_proba=True)\n",
        "f1_scorer = make_scorer(optimized_f1, needs_proba=True)\n",
        "mcc_scorer = make_scorer(optimized_mcc, needs_proba=True)\n",
        "\n",
        "# Declare the inner and outer cross-validation strategies\n",
        "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
        "outer_cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=10, random_state=0)\n",
        "\n",
        "def nested_repeated_cv(outcome, model, parameter_grid, min_follow_up_days, scaling, df, remove_cols):\n",
        "\n",
        "  x, y = get_x_y(df, outcome, min_follow_up_days, scaling, remove_cols)\n",
        "\n",
        "  # Inner cross-validation for parameter search\n",
        "  inner_model = HalvingGridSearchCV(estimator=model, param_grid=parameter_grid, cv=inner_cv, n_jobs=-1, factor=2, scoring='average_precision')\n",
        "\n",
        "  # Outer cross-validation to compute the testing score\n",
        "  cv_results = cross_validate(inner_model, x, y, cv=outer_cv, n_jobs=-1, scoring={'mcc': mcc_scorer, 'f1': f1_scorer, 'accuracy': acc_scorer, 'pr_auc': 'average_precision', 'roc_auc': 'roc_auc'})\n",
        "\n",
        "  print(\"Mean MCC: \"\n",
        "      f\"{cv_results['test_mcc'].mean():.3f} ± {cv_results['test_mcc'].std():.3f}\")\n",
        "  print(\"Mean F1: \"\n",
        "      f\"{cv_results['test_f1'].mean():.3f} ± {cv_results['test_f1'].std():.3f}\")\n",
        "  print(\"Mean Accuracy: \"\n",
        "      f\"{cv_results['test_accuracy'].mean():.3f} ± {cv_results['test_accuracy'].std():.3f}\")\n",
        "  print(\"Mean PR AUC: \"\n",
        "      f\"{cv_results['test_pr_auc'].mean():.3f} ± {cv_results['test_pr_auc'].std():.3f}\")\n",
        "  print(\"Mean ROC AUC: \"\n",
        "      f\"{cv_results['test_roc_auc'].mean():.3f} ± {cv_results['test_roc_auc'].std():.3f}\")"
      ],
      "metadata": {
        "id": "Jg60emeMwK-6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukIA11HJmEQn"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "01lHw2-dDfGs"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "weights = np.arange(0, 1, 0.1)\n",
        "lr_param_grid = {\n",
        "    'max_iter': [7500],\n",
        "    \"C\": np.arange(0.1, 5, 0.2),\n",
        "    'class_weight': [{0:x, 1:1-x} for x in weights],\n",
        "    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped_first_imp['complication_plate___exposure'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg_EE_3xP0Zl",
        "outputId": "db00ac4d-910d-4943-b840-283b62f7feda"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    229\n",
              "True      68\n",
              "Name: complication_plate___exposure, dtype: Int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUVKas4ODgeh"
      },
      "source": [
        "####Plate exposure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "boDd9D_llw9_"
      },
      "outputs": [],
      "source": [
        "remove_cols_pe = ['venous_anastomosis_type___end_end', 'venous_anastomosis_type___end_side', 'urkens_classification___c', 'surgery_duration_min']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAgXE56-hg_2",
        "outputId": "be41e00b-d4ee-4766-9a45-80fbcee9d79b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MCC: 0.151 ± 0.131\n",
            "Mean F1: 0.384 ± 0.118\n",
            "Mean Accuracy: 0.607 ± 0.242\n",
            "Mean PR AUC: 0.374 ± 0.071\n",
            "Mean ROC AUC: 0.643 ± 0.073\n"
          ]
        }
      ],
      "source": [
        "nested_cv(outcome='complication_plate___exposure', model=LogisticRegression(), parameter_grid=lr_param_grid, min_follow_up_days=60, scaling=RobustScaler(), df=df_dropped_first_cca, remove_cols=remove_cols_pe)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nested_repeated_cv(outcome='complication_plate___exposure', model=LogisticRegression(), parameter_grid=lr_param_grid, min_follow_up_days=60, scaling=RobustScaler(), df=df_dropped_first_cca, remove_cols=remove_cols_pe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBWUZRhIwyfs",
        "outputId": "16bb2f9f-7eaa-47ba-d212-a71dfecdd01f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MCC: 0.151 ± 0.139\n",
            "Mean F1: 0.420 ± 0.091\n",
            "Mean Accuracy: 0.542 ± 0.249\n",
            "Mean PR AUC: 0.381 ± 0.069\n",
            "Mean ROC AUC: 0.647 ± 0.076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp_cEDqNO8HE"
      },
      "outputs": [],
      "source": [
        "nested_cv_bootstrapping(outcome='complication_plate___exposure', model=LogisticRegression(), parameter_grid=lr_param_grid, min_follow_up_days=60, scaling=RobustScaler(), df=df_dropped_first_cca, remove_cols=remove_cols_pe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4lZqvTdDkFx"
      },
      "source": [
        "####Nonunion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "TJ418qRAsJ8o"
      },
      "outputs": [],
      "source": [
        "remove_cols_nu = ['venous_anastomosis_type___end_end', 'venous_anastomosis_type___end_side', 'urkens_classification___c', 'surgery_duration_min']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1RcxoK9R_4_",
        "outputId": "38ac64f2-f307-4fb9-cd31-0051def28a73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MCC: 0.180 ± 0.040\n",
            "Mean F1: 0.631 ± 0.003\n",
            "Mean Accuracy: 0.552 ± 0.004\n",
            "Mean PR AUC: 0.446 ± 0.006\n",
            "Mean ROC AUC: 0.512 ± 0.036\n"
          ]
        }
      ],
      "source": [
        "nested_cv(outcome='nonunion', model=LogisticRegression(), parameter_grid=lr_param_grid, min_follow_up_days=180, scaling=True, df=df_dropped_first_cca, remove_cols=remove_cols_nu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgPTePU3XGzf",
        "outputId": "54574cb2-0294-4ca3-e356-2b2d8f4be0aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MCC: 0.109 ± 0.091\n",
            "Mean F1: 0.569 ± 0.057\n",
            "Mean Accuracy: 0.521 ± 0.104\n",
            "Mean PR AUC: 0.447 ± 0.061\n",
            "Mean ROC AUC: 0.512 ± 0.057\n"
          ]
        }
      ],
      "source": [
        "nested_cv_bootstrapping(outcome='nonunion', model=LogisticRegression(), parameter_grid=lr_param_grid, min_follow_up_days=180, scaling=True, df=df_dropped_first_cca, remove_cols=remove_cols_nu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLUfcvFFDmpY"
      },
      "source": [
        "####Soft tissue complication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "nlYH78NYuwx5"
      },
      "outputs": [],
      "source": [
        "remove_cols_stx = ['venous_anastomosis_type___end_end', 'venous_anastomosis_type___end_side', 'urkens_classification___c']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4xVk1sxj7_U",
        "outputId": "44ad06aa-f234-48b1-dcbf-c48efda60c4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MCC: 0.099 ± 0.091\n",
            "Mean F1: 0.602 ± 0.084\n",
            "Mean Accuracy: 0.542 ± 0.047\n",
            "Mean PR AUC: 0.558 ± 0.040\n",
            "Mean ROC AUC: 0.556 ± 0.032\n"
          ]
        }
      ],
      "source": [
        "nested_cv(outcome='soft_tissue_complication', model=LogisticRegression(), parameter_grid=lr_param_grid, min_follow_up_days=30, scaling=True, df=df_dropped_first_cca, remove_cols=remove_cols_stx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8WwuLVEZ8Oh",
        "outputId": "71492ad8-e3f7-4388-e623-f882dff34845"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MCC: 0.248 ± 0.097\n",
            "Mean F1: 0.666 ± 0.088\n",
            "Mean Accuracy: 0.608 ± 0.065\n",
            "Mean PR AUC: 0.642 ± 0.090\n",
            "Mean ROC AUC: 0.642 ± 0.057\n"
          ]
        }
      ],
      "source": [
        "nested_cv_bootstrapping(outcome='soft_tissue_complication', model=LogisticRegression(), parameter_grid=lr_param_grid, min_follow_up_days=30, scaling=True, df=df_dropped_first_cca, remove_cols=remove_cols_stx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wmll9RJEDqST"
      },
      "source": [
        "####Wound infection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "xFgyMd2SBEii"
      },
      "outputs": [],
      "source": [
        "remove_cols_wi = ['venous_anastomosis_type___end_end', 'venous_anastomosis_type___end_side', 'urkens_classification___c']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5pULZ55pU_f",
        "outputId": "3899ddd8-da4d-4542-badd-dc3a21f37b5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MCC: 0.107 ± 0.096\n",
            "Mean F1: 0.426 ± 0.036\n",
            "Mean Accuracy: 0.578 ± 0.217\n",
            "Mean PR AUC: 0.320 ± 0.064\n",
            "Mean ROC AUC: 0.519 ± 0.058\n"
          ]
        }
      ],
      "source": [
        "nested_cv(outcome='wound_infection', model=LogisticRegression(), parameter_grid=lr_param_grid, min_follow_up_days=60, scaling=True, df=df_dropped_first_cca, remove_cols=remove_cols_wi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90nIzC5bgUyv",
        "outputId": "d48d6fce-fcb8-4bd8-e368-b44b94f08036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "1250 fits failed out of a total of 3750.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1000 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1241, in fit\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "250 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1216, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1181, in _fit_liblinear\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.41388889 0.41388889 0.43055556]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 1.         1.         0.98333333]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.35424603 0.4147619  0.45097171]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.58889576 0.38324062 0.39344581]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.31387071 0.32401635 0.30718983]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.71048602 0.7234673  0.73641622]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.33813983 0.33813983 0.33794431]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.52441438 0.52441438 0.52441438]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "1250 fits failed out of a total of 3750.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1000 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1241, in fit\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "250 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1216, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1181, in _fit_liblinear\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.5037037  0.51203704 0.53148148]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ...  1.  1.  1.]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.36300505 0.36300505 0.35555556]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.50077688 0.50629396 0.53553896]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.38381317 0.39752256 0.40009875]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.63625719 0.63428071 0.60951686]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.25752238 0.27569769 0.28262885]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.63902315 0.56213658 0.5316467 ]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "1250 fits failed out of a total of 3750.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1000 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1241, in fit\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "250 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1216, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1181, in _fit_liblinear\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.31798942 0.32910053 0.32910053]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ...  1.  1.  1.]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.46887566 0.41848189 0.57798077]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.39167568 0.44312318 0.54299786]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.31285184 0.2720564  0.24792732]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.36861029 0.26579113 0.31113098]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.31742787 0.30815273 0.34027095]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.49203478 0.48443035 0.50751197]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "1250 fits failed out of a total of 3750.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1000 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1241, in fit\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "250 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1216, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1181, in _fit_liblinear\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [      nan       nan       nan ... 0.5957672 0.5957672 0.6031746]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.98280423 0.98280423 0.98611111]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.38009319 0.37865019 0.38009319]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.87485906 0.87313394 0.87680157]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.41368996 0.28344102 0.38508918]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.6611306  0.31725133 0.39054533]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.41508355 0.41508355 0.44485212]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.45715238 0.45711268 0.58377267]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "625 fits failed out of a total of 1875.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "498 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1241, in fit\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "127 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1216, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1181, in _fit_liblinear\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.19444444 0.27777778 0.16666667 ...        nan        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.325      0.80555556 0.22222222 ...        nan        nan        nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.19444444 0.27777778 0.16666667 ... 0.45530303 0.51363636 0.42261905]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.325      0.80555556 0.22222222 ... 0.90216546 0.89713448 0.43129562]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.19444444 0.27777778 0.16666667 ... 0.42388843 0.42347792 0.4239259 ]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.325      0.80555556 0.22222222 ... 0.35074641 0.35173362 0.3514504 ]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.19444444 0.27777778 0.16666667 ... 0.29769429 0.29884995 0.29800389]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [0.325      0.80555556 0.22222222 ... 0.31443488 0.3164773  0.31459465]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "nested_cv_bootstrapping(outcome='wound_infection', model=LogisticRegression(), parameter_grid=lr_param_grid, min_follow_up_days=60, scaling=True, df=df_dropped_first_cca, remove_cols=remove_cols_wi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7opv3cYDs_H"
      },
      "source": [
        "####Flap loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEo87XTUxxA5"
      },
      "outputs": [],
      "source": [
        "remove_cols_fl = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmFZ7zKPlBtQ",
        "outputId": "13ef06f9-fee9-4ece-fdba-db3eba61d787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MCC: nan ± nan\n",
            "Mean F1: nan ± nan\n",
            "Mean Accuracy: nan ± nan\n",
            "Mean PR AUC: nan ± nan\n",
            "Mean ROC AUC: nan ± nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "1 fits failed out of a total of 3.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search_successive_halving.py\", line 273, in fit\n",
            "    super().fit(X, y=y, groups=groups, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\", line 874, in fit\n",
            "    self._run_search(evaluate_candidates)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search_successive_halving.py\", line 378, in _run_search\n",
            "    results = evaluate_candidates(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\", line 851, in evaluate_candidates\n",
            "    _warn_or_raise_about_fit_failures(out, self.error_score)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 367, in _warn_or_raise_about_fit_failures\n",
            "    raise ValueError(all_fits_failed_message)\n",
            "ValueError: \n",
            "All the 3750 fits failed.\n",
            "It is very likely that your model is misconfigured.\n",
            "You can try to debug the error by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3000 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1241, in fit\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "750 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1216, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1181, in _fit_liblinear\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        }
      ],
      "source": [
        "nested_cv(outcome='flap_loss', model=LogisticRegression(), parameter_grid=lr_param_grid, min_follow_up_days=0, scaling=True, df=df_dropped_first_cca, remove_cols=remove_cols_fl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TyuPQOIgW54",
        "outputId": "fcbf0cd9-3251-41be-fde6-4070045459bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "2500 fits failed out of a total of 3750.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "2000 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1241, in fit\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "500 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1216, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1181, in _fit_liblinear\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "1250 fits failed out of a total of 1875.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1000 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1241, in fit\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "250 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1216, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1181, in _fit_liblinear\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "313 fits failed out of a total of 939.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "63 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1216, in fit\n",
            "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\", line 1181, in _fit_liblinear\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "250 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1241, in fit\n",
            "    raise ValueError(\n",
            "ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the train scores are non-finite: [nan nan nan ... nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "nested_cv_bootstrapping(outcome='flap_loss', model=LogisticRegression(), parameter_grid=lr_param_grid, min_follow_up_days=0, scaling=True, df=df_dropped_first_cca, remove_cols=remove_cols_fl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySF20KJfAvLG"
      },
      "source": [
        "##Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJMZoCCBDxNt"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [50, 100, 500, 1000, 5000],\n",
        "    'max_depth': np.arange(2, 8, 1),\n",
        "    'min_samples': np.arange(0, 1, 0.1),\n",
        "    'min_weight_fraction_leaf': np.arange(0, 1, 0.1),\n",
        "    'max_features': np.arange(0, 1, 0.1)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTXS3UC7DyVE"
      },
      "source": [
        "####Plate exposure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJCnUO7kAy08"
      },
      "outputs": [],
      "source": [
        "nested_cv(outcome='complication_plate___exposure', model=RandomForestClassifier(n_jobs=-1, random_state=0), parameter_grid=rf_param_grid, min_follow_up_days=90, scaling=False, df=df_all_levels_cca, remove_cols=remove_cols_pe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLEnIg1JrkyA"
      },
      "outputs": [],
      "source": [
        "nested_cv_bootstrapping(outcome='complication_plate___exposure', model=RandomForestClassifier(n_jobs=-1, random_state=0), parameter_grid=rf_param_grid, min_follow_up_days=90, scaling=False, df=df_all_levels_cca, remove_cols=remove_cols_pe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wWCbrS7_MYA"
      },
      "source": [
        "####Nonunion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ5fisP-_PbK"
      },
      "outputs": [],
      "source": [
        "nested_cv(outcome='nonunion', model=RandomForestClassifier(n_jobs=-1, random_state=0), parameter_grid=rf_param_grid, min_follow_up_days=180, scaling=False, df=df_all_levels_cca, remove_cols=remove_cols_nu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phP2IxULrnW2"
      },
      "outputs": [],
      "source": [
        "nested_cv_bootstrapping(outcome='nonunion', model=RandomForestClassifier(n_jobs=-1, random_state=0), parameter_grid=rf_param_grid, min_follow_up_days=180, scaling=False, df=df_all_levels_cca, remove_cols=remove_cols_nu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mskyn6qDuJz"
      },
      "source": [
        "####Soft tissue complication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcDsj7oDCLIn"
      },
      "outputs": [],
      "source": [
        "nested_cv(outcome='soft_tissue_complication', model=RandomForestClassifier(n_jobs=-1, random_state=0), parameter_grid=rf_param_grid, min_follow_up_days=180, scaling=False, df=df_all_levels_cca, remove_cols=remove_cols_stx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deHI7niHrpsb"
      },
      "outputs": [],
      "source": [
        "nested_cv_bootstrapping(outcome='soft_tissue_complication', model=RandomForestClassifier(n_jobs=-1, random_state=0), parameter_grid=rf_param_grid, min_follow_up_days=180, scaling=False, df=df_all_levels_cca, remove_cols=remove_cols_stx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxdgc3COGYS5"
      },
      "source": [
        "####Wound infection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7MoGzjFGZw6"
      },
      "outputs": [],
      "source": [
        "nested_cv(outcome='wound_infection', model=RandomForestClassifier(n_jobs=-1, random_state=0), parameter_grid=rf_param_grid, min_follow_up_days=180, scaling=False, df=df_all_levels_cca, remove_cols=remove_cols_wi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lckFb4aHrr94"
      },
      "outputs": [],
      "source": [
        "nested_cv_bootstrapping(outcome='wound_infection', model=RandomForestClassifier(n_jobs=-1, random_state=0), parameter_grid=rf_param_grid, min_follow_up_days=180, scaling=False, df=df_all_levels_cca, remove_cols=remove_cols_wi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOWpxJr1IIDP"
      },
      "source": [
        "####Flap loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npFDnd0QITO5"
      },
      "outputs": [],
      "source": [
        "nested_cv(outcome='flap_loss', model=RandomForestClassifier(n_jobs=-1, random_state=0), parameter_grid=rf_param_grid, min_follow_up_days=0, scaling=False, df=df_all_levels_cca, remove_cols=remove_cols_fl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDclN5Nzrt-K"
      },
      "outputs": [],
      "source": [
        "nested_cv_bootstrapping(outcome='flap_loss', model=RandomForestClassifier(n_jobs=-1, random_state=0), parameter_grid=rf_param_grid, min_follow_up_days=0, scaling=False, df=df_all_levels_cca, remove_cols=remove_cols_fl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_LnRR0DIc8T"
      },
      "source": [
        "##kNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5dQMAoGKSSY"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_param_grid = {\n",
        "    'n_neighbors': np.arange(2, 8, 1),\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'leaf_size': np.arange(5, 45, 10),\n",
        "    'p': np.arange(0.5, 5, 0.5)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPoEHisjeyJo"
      },
      "outputs": [],
      "source": [
        "nested_cv(outcome='complication_plate___exposure', model=KNeighborsClassifier(n_jobs=-1), parameter_grid=knn_param_grid, min_follow_up_days=60, scaling=True, df=df_all_levels_cca, remove_cols=remove_cols_pe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmKqa6VdQvBG"
      },
      "source": [
        "####Nonunion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQc5vl79QwQB"
      },
      "outputs": [],
      "source": [
        "nested_cv(outcome='nonunion', model=KNeighborsClassifier(n_jobs=-1), parameter_grid=knn_param_grid, min_follow_up_days=180, scaling=True, df=df_all_levels_cca, remove_cols=remove_cols_nu)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Old"
      ],
      "metadata": {
        "id": "mCuubHA_BSQZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "td9Xw6lm8Cv-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold, HalvingGridSearchCV\n",
        "from sklearn.metrics import make_scorer, matthews_corrcoef, f1_score, accuracy_score, average_precision_score, roc_auc_score\n",
        "\n",
        "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
        "\n",
        "def nested_cv_bootstrapping(outcome, model, parameter_grid, min_follow_up_days, scaling, df, remove_cols):\n",
        "\n",
        "  metrics = {'f1': [], 'mcc': [], 'accuracy': [], 'pr_auc': [], 'roc_auc': []}\n",
        "\n",
        "  n_bootstrap = 10\n",
        "  x, y = get_x_y(df, outcome, min_follow_up_days, scaling, remove_cols)\n",
        "\n",
        "  for i in range(n_bootstrap):\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True, stratify=y, random_state=i)\n",
        "    print(y_train.value_counts())\n",
        "\n",
        "    # Inner loop: Grid search for hyperparameter tuning\n",
        "    inner_model = HalvingGridSearchCV(estimator=model, param_grid=parameter_grid, cv=inner_cv, factor=2, n_jobs=-1, scoring='average_precision')\n",
        "    inner_model.fit(x_train, y_train)\n",
        "\n",
        "    # Get the best hyperparameters from the inner loop\n",
        "    best_params = inner_model.best_params_\n",
        "\n",
        "    # Evaluate the selected hyperparameters on the remaining 30% of the data\n",
        "    model.set_params(**best_params)\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict_proba(x_test)\n",
        "\n",
        "    metrics['f1'].append(optimized_f1(y_test, y_pred[:, 1]))\n",
        "    metrics['mcc'].append(optimized_mcc(y_test, y_pred[:, 1]))\n",
        "    metrics['accuracy'].append(optimized_accuracy(y_test, y_pred[:, 1]))\n",
        "    metrics['pr_auc'].append(average_precision_score(y_test, y_pred[:, 1]))\n",
        "    metrics['roc_auc'].append(roc_auc_score(y_test, y_pred[:, 1]))\n",
        "\n",
        "\n",
        "  print(\"Mean MCC: \"\n",
        "      f\"{np.mean(metrics['mcc']):.3f} ± {np.std(metrics['mcc']):.3f}\")\n",
        "  print(\"Mean F1: \"\n",
        "      f\"{np.mean(metrics['f1']):.3f} ± {np.std(metrics['f1']):.3f}\")\n",
        "  print(\"Mean Accuracy: \"\n",
        "      f\"{np.mean(metrics['accuracy']):.3f} ± {np.std(metrics['accuracy']):.3f}\")\n",
        "  print(\"Mean PR AUC: \"\n",
        "      f\"{np.mean(metrics['pr_auc']):.3f} ± {np.std(metrics['pr_auc']):.3f}\")\n",
        "  print(\"Mean ROC AUC: \"\n",
        "      f\"{np.mean(metrics['roc_auc']):.3f} ± {np.std(metrics['roc_auc']):.3f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1YCeJ8o9LykeewEBhhIL_d6nHNE3VcARS",
      "authorship_tag": "ABX9TyPgS2C9As1IchOvb7Qsg4ZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}