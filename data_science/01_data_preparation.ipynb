{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONF62Hc6+W8eoOdZ/1apbS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philipp-lampert/mymandible/blob/main/data_science/01_data_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation\n",
        "This notebook prepares the raw data for further analyses by correctly defining missing values and column types."
      ],
      "metadata": {
        "id": "VhB3OcNIaASK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option(\"display.max_rows\", None)"
      ],
      "metadata": {
        "id": "SuW9JDqUb3e8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now ready to import the dataset from the [mymandible](https://github.com/philipp-lampert/mymandible) Github repository. This is the unprocessed CSV file exported directly from the associated [RedCap](https://www.project-redcap.org/) project.\n",
        "\n",
        "We prevent automatic detection of missing values by setting `na_filter = False` as this would replace missing values with Numpy's `np.nan` which - in contrast to Panda's newer `pd.NA` - does not allow for nullable boolean and integer columns.\n",
        "\n"
      ],
      "metadata": {
        "id": "eP4BPR4elmPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/philipp-lampert/mymandible/main/data_science/data/pipeline/raw.csv\", na_filter = False)\n",
        "df = df.replace([\"NaN\", \"\"], pd.NA)"
      ],
      "metadata": {
        "id": "bCIPgexfb-t9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For multiple-choice variables, RedCap exports each choice as a binary column with a naming convention of `variable___option`. Importantly, missing values are not stored directly inside each column but in an additional binary column named `variable___nan`. Therefore, we have to set each row of `variable___option` to `NaN` whenever `variable___nan == 1`."
      ],
      "metadata": {
        "id": "MXNXwlo7Dc1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nan_columns = df.filter(like = \"___nan\").columns\n",
        "multiple_choice_variables = [name.split(\"___nan\")[0] for name in nan_columns]\n",
        "\n",
        "for variable in multiple_choice_variables:\n",
        "  row_with_nan = df[f\"{variable}___nan\"] == 1\n",
        "  columns = df.columns[df.columns.str.startswith(variable)]\n",
        "  df.loc[row_with_nan, columns] = pd.NA\n",
        "  df = df.drop(f\"{variable}___nan\", axis=1)"
      ],
      "metadata": {
        "id": "TzTP5qZwITUs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With missing values now being correctly represented in our dataframe, let's remove the auto-generated RedCap columns that are only relevant during data collecting."
      ],
      "metadata": {
        "id": "WMCbGl_AXMDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop([\"id\", \"predictors_complete\", \"outcomes_complete\", \"imaging_complete\"], axis = 1)"
      ],
      "metadata": {
        "id": "5cCeAh9KJayH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will convert each column to its appropriate datatype (boolean, integer, categorical etc.)."
      ],
      "metadata": {
        "id": "JE_NyVPcd96O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_types = {\n",
        "        \"boolean\": {\n",
        "            \"sex_female\",\n",
        "            \"skin_transplanted\",\n",
        "            \"flap_loss\",\n",
        "            \"wound_infection\",\n",
        "            \"nonunion\",\n",
        "            \"tmj_luxation\",\n",
        "        },\n",
        "        \"category\": {\n",
        "            \"indication\",\n",
        "            \"prior_flap\",\n",
        "            \"flap_revision\",\n",
        "            \"flap_donor_site\",\n",
        "            \"plate_type\",\n",
        "            \"long_plate_thickness\",\n",
        "            \"mini_plate_thickness\",\n",
        "            \"tmj_replacement_type\",\n",
        "            \"flap_segment_count\",\n",
        "            \"flap_loss_type\",\n",
        "            \"imaging\",\n",
        "        },\n",
        "        \"string\": {\n",
        "            \"which_autoimmune_disease\",\n",
        "            \"which_bleeding_disorder\",\n",
        "        },\n",
        "        \"UInt8\": {\"age_surgery_years\", \"height_cm\", \"weight_kg\"},\n",
        "        \"UInt16\": {\"surgery_duration_min\"},\n",
        "        \"Float32\": {\"bmi\"},\n",
        "    }\n",
        "\n",
        "for column in df.columns:\n",
        "    # All multiple-choice columns have three underscores in their name\n",
        "    if \"___\" in column:\n",
        "        df[column] = df[column].astype(\"boolean\")\n",
        "    elif column in data_types[\"boolean\"]:\n",
        "        df[column] = np.where(\n",
        "            df[column] == \"True\",\n",
        "            True,\n",
        "            np.where(df[column] == \"False\", False, df[column]),\n",
        "        )\n",
        "        df[column] = df[column].astype(\"boolean\")\n",
        "    elif column.startswith(\"days_to_\"):\n",
        "        df[column] = df[column].astype(\"UInt16\")\n",
        "    else:\n",
        "        for data_type in [\"category\", \"string\", \"UInt8\", \"UInt16\", \"Float32\"]:\n",
        "            if column in data_types[data_type]:\n",
        "                df[column] = df[column].astype(data_type)"
      ],
      "metadata": {
        "id": "7213tYP-Ekak"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That looks as expected. We can now save the dataframe in the Parquet format to preserve the data types, something that would not be possible in the CSV format."
      ],
      "metadata": {
        "id": "C8XPBIE1IRz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_parquet('02_dtypes.parquet')"
      ],
      "metadata": {
        "id": "_EDK0gfOKeNh"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}